{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f083077",
   "metadata": {},
   "source": [
    "**In this workshop we will analyze the Chicago city's transit ridership data to answer the following questions:**\n",
    "\n",
    "1. Which route has the highest average ridership? Is it also the most popular route on Saturdays or on Sundays and Holidays?\n",
    "2. Why is the route so popular?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302c7ef4",
   "metadata": {},
   "source": [
    "# Python Programming Language for Data Analysis with Pandas Library\n",
    "\n",
    "Python programming language has numerous functions. These functions are organized into modules. **Modules** are python scripts that contain Python objects. In order to use the objects inside these modules (or commonly known as libraries), we must first **import** either the entire module or specific objects in it. \n",
    "\n",
    "**`Pandas` (Python for Data Analysis)** is a popular python library. We will use this library extensively in this workshop. This library is automatically installed during Anaconda installation. It is also installed and available on Google Colab or UofT Jupyter Hub. \n",
    "\n",
    "Other popular python libraries are **`NumPy` (Numerical Python)** and **`matplotlib`** used for scientific computing and visualization, respectively. We will import these libraries too. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ab3abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a3c083",
   "metadata": {},
   "source": [
    "Let's take a moment to understand the three lines of code above. \n",
    "\n",
    "1. First, the keyword `import` is available directly in Python and is used to find and load the objects of a Python module into the Python environment we are working in. The `import` keyword is followed by the module name we are looking to import. So, here we have imported the `pandas`, the `numpy` and the `matplotlib` libraries. \n",
    "\n",
    "2. Often instead of importing the libraries with its original name, we import them with an alias using the `as` keyword. This is useful because everytime we want to use a function inside the library, instead of typing the full name of the module, we can just type the short alias. So `pd` for `pandas` and `np` for numpy and so on. \n",
    "\n",
    "Notice that the last line of import is slightly different as it contains a `.`, which is called the **dot operator**:\n",
    "1. The dot operator is used to access items that are inside of the object. Simply type the name of the object and then `.` followed by the item to access. \n",
    "2. Sometimes the Python libraries are so big that they need to be managed inside multiple sub-modules. Each sub-module of a module can be accessed by using the `.`. In this example, `pyplot` sub-module is imported instead of the entire `matplotlib` module. Then, the alias `plt` is given to this sub-module. \n",
    "\n",
    "Throughout this tutorial, we will make use of the dot operator like this to access the objects available in a module. Let's begin by using the `.` to access the function `read_csv` available in the pandas library. It allows us to read a csv file.\n",
    "\n",
    "<span style='color:Blue'> A **function** in python is a block of code that has been attached to a name. So `read_csv`, underneath its name, is a whole bunch of codes that run to ensure the file we want to read is imported into the python environment. We do not need to see these codes but we do need to look at the [documentation](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html) of the function so that we can understand how to use it. For example, we need to know which parameters the function takes and provide value for at least those parameters that are mandatory. </span>\n",
    "\n",
    "According to the documentation, the first parameter of `read_csv` is the `filepath_or_buffer`. It is a mandatory parameter and takes as value the path to the file you want to load, including the file name. The parameters and their corresponding values are inserted inside the parenthesis, `( )` which must be placed right next to the function without any spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b2af6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import file using the full path including the file name\n",
    "filepath = \"C:\\\\Users\\\\niti.mishra\\\\Documents\\\\2_TDMDAL\\\\workshop\\\\rcfta_datathonworkshop\\\\cta-ridership-original.csv\"\n",
    "pd.read_csv(filepath_or_buffer=filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e41eb4f",
   "metadata": {},
   "source": [
    "Here, in the first line of code we created a variable called the filepath and then used that variable as an argument to the parameter `filepath_or_buffer`.\n",
    "\n",
    "<span style='color:Blue'> A **variable** is an object whose name refers to some value. Python provides the **assignment operator**, `=`, to assign values to a variable. There are some best practices and rules surrounding [naming variables in Python](https://www.w3schools.com/python/gloss_python_variable_names.asp). If naming conventions are not followed properly, you will get an error. </span>\n",
    "\n",
    "It is particularly helpful to store values as variables, so that we can manipulate them easily. For example, in the second line of code above, we imported the data but we cannot work with this data yet. To do so, we need to save the data into a variable. Let's do that below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebf4856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import file using the file name only\n",
    "# works only if the notebook and data file are in the same folder\n",
    "data = pd.read_csv(filepath_or_buffer=\"cta-ridership-original.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5af6931",
   "metadata": {},
   "source": [
    "Now the data is stored in a variable named `data`. We can use the `head` function of `pandas` to display the first five rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17db019",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3bd2f5",
   "metadata": {},
   "source": [
    "We can also provide arguments for additional parameters in a function. See example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e148b5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"cta-ridership-original.csv\", sep=\",\", header=[0,1], index_col=0 )\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf140437",
   "metadata": {},
   "source": [
    "1. Notice here I did not specify the parameter `filepath_or_buffer` anymore and it still worked. We do not need to specify the parameter name as long as we retain the order of those parameter. \n",
    "\n",
    "2. Adding `sep` parameter here makes no difference because even without specifying it the value does not change but it is helpful from code readability perspective. \n",
    "\n",
    "3. The default value for `header` parameter was 0 and here I changed that to 0 and 1, which is why the first and the second rows were used as the column names. This is just for demonstration. Obviously, in our data only the first row qualifies as the header, therefore we do not need to specify this parameter. \n",
    "\n",
    "4. Finally, for `index_col` parameter, a value 0 signifies that the first column should be used as the index column. Hence you see that the original pandas index (0, 1, 2, ... 29540) is replaced with the first column \"route\". You may or may not want to do this. \n",
    "\n",
    "<span style='color:Blue'> By now you must have noticed that in Python **index** starts from 0 not 1! </span>\n",
    "\n",
    "Let's redo this with corrections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf84257b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"cta-ridership-original.csv\", sep=\",\", header=0, index_col=None)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d36812e",
   "metadata": {},
   "source": [
    "Every variable has a data type. For example, a variable created using `pandas`, will be either a `DataFrame` or a `Series`. Since the variable data above has two dimensions (rows and columns), it is a `DataFrame`. \n",
    "\n",
    "<span style='color:Blue'> There are [standard Python](https://upload.wikimedia.org/wikipedia/commons/1/10/Python_3._The_standard_type_hierarchy.png) **data types** and then, there are data types that are borrowed from external Python modules or libraries, such as the `DataFrame`. Data types are important to know because they define what we can do with that variable. Python provides the `type` function to check the data type of a variable. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f23125",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(filepath))\n",
    "type(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb54873e",
   "metadata": {},
   "source": [
    "In the first line of code, \n",
    "1. `print`, the most commonly used Python function, is used to display the result of an operation on our console.\n",
    "2. `print` function here displays the result of the function `type` applied on the variable filepath. The printed result tells us that the filepath variable belongs to data type `string`, which is a standard Python data type. \n",
    "\n",
    "<span style='color:Blue'> **Strings** are the most complex of the four basic data types available in Python. The other data types are `float`, `integer` and `bool`. Formally, strings are arrays of bytes representing unicode characters, which means characters, symbols, numbers, whitespaces, etc. are all strings. Strings can be created in Python by enclosing just about any characters inside single or double quotes</span>\n",
    "\n",
    "In the second line of code, \n",
    "1. `print` function is not used because in jupyter notebook, the result of the operation of the last line is by default displayed on the console. \n",
    "2. The result tells us that the variable data belongs to a `pandas.core.frame.DataFrame`, in short the `DataFrame`, type. \n",
    "\n",
    "A Python built-in function called `dir` lists the available functions to a variable. This is helpful to know what operations are possible on that variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d23055",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dir(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c63cf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03aba7a9",
   "metadata": {},
   "source": [
    "<span style='color:Blue'> Notice that different functions are available to these variables of different data types. Since these functions are specific to these data types, they are called **methods**, which is what we will also call them going forward. To access the methods available to an object, we simply use the dot operator, `.`. </span>\n",
    "\n",
    "Let's try a method on the variable filepath and the variable data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1735e660",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(filepath)\n",
    "split_string = filepath.split('\\\\')\n",
    "split_string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a89c2b",
   "metadata": {},
   "source": [
    "The [`split` method](https://www.w3schools.com/python/ref_string_split.asp) splits the string at the specified separator. If no separator is given, the split is done at whitespace. The result of the split method is a `list`, which is another data type. More on that later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1160a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcafe1b",
   "metadata": {},
   "source": [
    "In this second example, the `info` method of `pandas`, results into a neat display of some useful information of the data.\n",
    "1. First, it shows that the data has 29541 rows.\n",
    "2. These rows are indexed as a range from 0 to 29540. \n",
    "3. Then we see that there are 7 columns. \n",
    "4. For each column, the column index number, column name, number of non-missing values and the data type is given. \n",
    "\n",
    "In `pandas`, the `object` data type is similar to Python's `string` data type.\n",
    "\n",
    "Let's explore some more common methods of a `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3283fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef599ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape  # notice this one does not use parenthesis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b8f08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9992f809",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4698459",
   "metadata": {},
   "source": [
    "Notice in the last example, applying `sum` in an object column results in concatenation of the strings in that column. This results isn't helpful to us and so we can take the sum of only the columns where mathematical addition is possible. \n",
    "\n",
    "To extract select columns, we need to index them. In Python square brackets, `[ ]`, are the **index operator**. This indexing role of the square brackets is also extended to the `pandas` module. To use it, we can insert either the index position or the index name of the item we want to extract inside the `[ ]`. Then, we can apply the `sum` method in the resulting subset of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0154a449",
   "metadata": {},
   "outputs": [],
   "source": [
    "monthtotal = data['MonthTotal']\n",
    "monthtotal.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6816a677",
   "metadata": {},
   "source": [
    "If we want to extract more than one item then we have to put them in a list. \n",
    "\n",
    "<span style='color:Blue'> **Lists** are simply a collection of items. Each item in a list can belong to any data type. The important thing about the list is that they are a sequence and thus, can be indexed using index numbers and items can be added and deleted from it. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e812708",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_columns = ['Avg_Weekday_Rides', 'Avg_Saturday_Rides', 'Avg_Sunday-Holiday_Rides', 'MonthTotal']\n",
    "data[list_of_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db36535",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[list_of_columns].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99660c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[list_of_columns].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abd0d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[list_of_columns].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764124f1",
   "metadata": {},
   "source": [
    "Let's go to the categorical variables now. We can find the number of unique items and their counts. To do so we can use the `nunique` and the `value_counts` methods, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76be863",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['route'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f575d808",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['routename'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad745be",
   "metadata": {},
   "source": [
    "Notice that some routes have multiple route names. To find out which routenames have the same route, we can first isolate the two columns and then apply the `drop_duplicates` method to remove any duplicated rows. \n",
    "\n",
    "Then, in the resulting dataframe, we can apply the `duplicated` method, which will result in a Boolean (True or False) `Series`. Recall, that a `Series` is a Pandas data structure designed to store information of one variable only i.e. one-dimensional data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38a352c",
   "metadata": {},
   "outputs": [],
   "source": [
    "allroutes = data[['route','routename']].drop_duplicates()\n",
    "allroutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33391c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "allroutes.duplicated(['route'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a19456",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(allroutes.duplicated(['route']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05abcdd",
   "metadata": {},
   "source": [
    "This resulting series can now be used to filter the rows of our interest. Earlier we learnt how to select columns and now this is about selecting rows. In both cases we need to use the index operator,`[ ]`. Inside the index operator we can insert this Boolean series. The index positions where the value is False, the corresponding rows are not selected and if the values are True, the corresponding rows will be selected. \n",
    "\n",
    "The [`duplicated` method](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.duplicated.html) offers a `keep` parameter. We will set this parameter's value to False so that we can see both routenames. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330d9f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicated = allroutes[allroutes.duplicated(['route'], keep=False)]\n",
    "duplicated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22dbcbc2",
   "metadata": {},
   "source": [
    "Similarly, you can create Boolean series that satisfy some condition and then use it to select the desired rows. A common way of creating conditions in Python is by using the **comparision operators**. [These operators](https://www.w3schools.com/python/python_operators.asp) allow us to compare values greater than, less than, equal to and so on.  \n",
    "\n",
    "Let's take another example where we want to select only those rows that belong to the routename Cicero. For this, we can create a condition that checks which rows of the column routename is equal to \"Cicero\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c12ed13",
   "metadata": {},
   "outputs": [],
   "source": [
    "cicero_only_condition = data['routename']=='Cicero'\n",
    "cicero_only_condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3921808b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cicero_only = data[cicero_only_condition]\n",
    "cicero_only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f906213",
   "metadata": {},
   "source": [
    "Here is another example, that uses the conditional operator, `>=` to select rows that have \"Avg_Sunday-Holiday_Rides\" column's value greater than and equal to 20,000. Then, we use the `sort_values` method to view the top routes and months during Sundays and holidays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274d3934",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_holiday_rides = data[data['Avg_Sunday-Holiday_Rides'] >= 20000]\n",
    "high_holiday_rides.sort_values('Avg_Sunday-Holiday_Rides', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f814d8b0",
   "metadata": {},
   "source": [
    "So, the results indicate that \"Shuttle/Special Event Route\" on the month beginning on May 2008 had the highest number of average ride on Sunday and Holiday. We also see that the route 79, showed up quite often on this list indicating it is a busy sunday and holiday route. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be2c9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_holiday_rides['routename'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59de9de",
   "metadata": {},
   "source": [
    "So far, we learned how to select rows and how to select columns separately. What about selecting both rows and columns at once? For this we need to first review Python index a little. Then we will get back to index in Pandas, which borrows some of the syntax from Python index.\n",
    "\n",
    "<span style='color:Blue'> By now we know that to extract items in Python, we can use the `[ ]` operator. Strictly in basic Python i.e. when not using any other Python libraries, we can use the index number to specify which item we want to extract. **Index number** is the position of the item in a sequence and Python index number starts from 0.</span>\n",
    "\n",
    "For example, the variable list_of_columns os a `list` in Python, which is a sequence and thus, the first item in this `list` can be extracted using the index number 0 inside the `[ ]`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ab6fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d64e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_columns[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914302eb",
   "metadata": {},
   "source": [
    "<span style='color:Blue'> To extract more than one item, we need to specify the start and stop position separated by `:`. Items starting from the start position and upto but not including the stop position will be returned. If no position is defined then the items are returned from the begining or up to the end.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d86c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_columns[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6c4192",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_columns[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b745e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_columns[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8699d2a0",
   "metadata": {},
   "source": [
    "<span style='color:Blue'> Python also makes it easy to extract the last item of the list by providing negative indexing abilities. Negative indexing does NOT start from 0 but -1. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f14282",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_columns[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bef5f6",
   "metadata": {},
   "source": [
    "Now, let's convert the column routename to a `list` data type. Then, we can index items inside it similarly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b571a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "routename = list(data['routename'])\n",
    "routeone = routename[0]\n",
    "routeone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7765a1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(routeone)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fb6e7f",
   "metadata": {},
   "source": [
    "So the first item of the column routename is \"Indiana/Hyde Park\", which is of data type string. String is also a sequence and therefore, can be indexed similarly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761c0d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "routeone[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1f40ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "routeone[7:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ad6ffc",
   "metadata": {},
   "source": [
    "String offers a useful `find` method, where we can input the character we want to find the index for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd1c258",
   "metadata": {},
   "outputs": [],
   "source": [
    "routeone.find('/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17a3c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "routeone[7]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e38567",
   "metadata": {},
   "source": [
    "These operations can be chain altogether in one line. But be careful, code readibility is important and sometime, you may want to break the code in couple of lines for that reason. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028ff165",
   "metadata": {},
   "outputs": [],
   "source": [
    "routeone[0:routeone.find('/')] # there are other ways to do this as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf255562",
   "metadata": {},
   "source": [
    "Lists only have one index but pandas `DataFrame` has two. This should make sense because list only has one dimension while the pandas `DataFrame` has two dimensions. One for rows and the other for columns, both of which can be indexed in two different ways:\n",
    "- Rows\n",
    "    1. row index numbers \n",
    "    2. row index label/name\n",
    "- Columns\n",
    "    1. column index numbers\n",
    "    2. columns index label/name\n",
    "    \n",
    "So far we had only seen indexing using the item position i.e. index numbers. Now with `DataFrame`, each index position also has a corresponding index label or name, which can also be used to select that row or column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838ec8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.index  # get the row labels/names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55bb65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.index[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cfcc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns # get the columns labels/names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e15e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb337d79",
   "metadata": {},
   "source": [
    "To index both rows and columns at once, we must use either `loc` or `iloc` method. To use index labels or names, we must combine it with the `loc` method and to use the index numbers, we must combine it with the `iloc` method. The important thing to remember now is that a comma `,` separates the space for indexing rows and columns. Then the rest of the indexing method is borrowed from standard Python. \n",
    "\n",
    "See an example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ddac39",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[ [1,3,7,9], ['route', 'MonthTotal']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e46f590",
   "metadata": {},
   "source": [
    "We can also combine this with conditional indexing. For example, to select only the routenames of only those rows that have higher than average value for the columns \"MonthTotal\", we can use the `loc` method combined with index labels and the boolean `Series` defining this condition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25e3f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "mthtotal_avgcond = data['MonthTotal'].mean()\n",
    "mthtotal_avgcond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754fab7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['MonthTotal'] >= mthtotal_avgcond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f092cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mthtotal_avg = data.loc[data['MonthTotal'] >= mthtotal_avgcond, 'routename']\n",
    "mthtotal_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a5c4d9",
   "metadata": {},
   "source": [
    "Now lets use the `iloc` method by indicating the index number instead of index labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9c6681",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfe0560",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c517024d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[0:5,0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7394bba8",
   "metadata": {},
   "source": [
    "While `pandas` by default sets row index as a range of number from 0 to the length of the `DataFrame`, it also provides the flexibility to assign our own index values. We can use the `set_index` method to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cc0f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.set_index('routename').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cd7ee6",
   "metadata": {},
   "source": [
    "The above line of code gives us the desired result but it does not change the original `DataFrame`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d50a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5536f816",
   "metadata": {},
   "source": [
    "To save the result of the operation of changing the index, we must use the parameter `inplace` and set its value to True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbf1a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.set_index('routename', inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e286ec",
   "metadata": {},
   "source": [
    "It is also possible to undo the index operation and go back to `pandas`'s default index labels. We do that using `reset_index` method. Again, to change the original dataframe with this operation, set the value of `inplace` parameter to True. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7077ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.reset_index(inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041c9805",
   "metadata": {},
   "source": [
    "Note that when testing, it is advisable that you do not set `inplace` parameter value to True. Do so only after you are sure that's the change you want permanently. \n",
    "\n",
    "\n",
    "Now, we will look at another very common and complex data type, the `datatime`. Note that we have the column Month_Beginning in our data, which is currently stored as an object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c7a327",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c749f3",
   "metadata": {},
   "source": [
    "What if we can store this information in a way that is smart enough to know the year, the month and other details pertaining to this date? We can do that using the `to_datetime` method offered in `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11e2b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Month_Beginning'] = pd.to_datetime(data['Month_Beginning'], format='%m/%d/%Y')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c5f8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6545a184",
   "metadata": {},
   "source": [
    "The `to_datetime` method of `pandas` is actually an extension of the Python's `datetime` module. The `format` parameter takes specific values that help the program understand the format the date is presented in our data. Here is [a list of possible values](https://strftime.org/). \n",
    "\n",
    "Now that the column Month_Beginning is a `datetime` object, it offers us additional methods to easily extract the year, the month and so on. We can use `year` and create a new columns in our `DataFrame`, which will store that year value for each row. To create a new column, we simply use the `[ ]` and provide a meaningful name inside it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a89016",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Month_Beginning_year'] = data['Month_Beginning'].dt.year\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3452eab2",
   "metadata": {},
   "source": [
    "Let's try again with the `month` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c28d62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Month_Beginning_month'] = data['Month_Beginning'].dt.month\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed83bce0",
   "metadata": {},
   "source": [
    "Now we are going to see some of the more powerful data analysis features of `pandas`. These features are what made many data analysts move from excel to python for data analysis. \n",
    "\n",
    "We learned earlier that routename 79th was a popular route during Sundays and Holidays. Let's look into the details of this route further. For that we can create a new `DataFrame`, which contains only the rows that belongs to the routename 79th. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040ef88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "routename_79th = data[data['routename']=='79th']\n",
    "routename_79th"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2da95a",
   "metadata": {},
   "source": [
    "There is a `groupby` method available that allows us to easily extract summary statistics of the data for different groups. \n",
    "\n",
    "For example, we can group the above data for routename 79th into years and see the average trend of ridership for each year. To group the data by years, we must specify the columns that have the year information and then we can calculate mean using the `mean` method on the resulting `DataFrameGroupBy` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23987396",
   "metadata": {},
   "outputs": [],
   "source": [
    "routename_79th.groupby('Month_Beginning_year').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e080e75",
   "metadata": {},
   "source": [
    "Note that we got yearly mean of even the column Month_Beginning_month, which does not make much sense. We can omit that. \n",
    "\n",
    "Let's say we are interested only in the column MonthTotal, we can simply take the two columns of our interest and run the `groupby` method and our result will be a nice table that can be easily plotted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3ca80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "routename79th_yearlyavg = routename_79th[['Month_Beginning_year','Avg_Sunday-Holiday_Rides']].groupby('Month_Beginning_year').mean()\n",
    "routename79th_yearlyavg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109c2f67",
   "metadata": {},
   "source": [
    "The `plot` method can be used to plot `pandas` data. `Pandas` is smart enough to understand that the row index is supposed to be the x-axis and the values will be the y-axis. `plt.show()` is used to display the plot on your console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b952136",
   "metadata": {},
   "outputs": [],
   "source": [
    "routename79th_yearlyavg.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fae5124",
   "metadata": {},
   "source": [
    "We have the plot but it can do with a few changes. First, we can add a nice title to it. Secondly, the x-axis are displayed as float numbers. This does not make much sense for year values. To change this to integer and to add the title for the plot, we can combine elements of `matplotlib` sub-modules:\n",
    "1. First, we set up two variables, fig and ax, using the `subplots` function of the `pyplot` submodule of `matplotlib`.\n",
    "2. Then, we can use `plot` method and set `ax` parameter to the variable ax. This will ensure that any method available to `ax` variable will apply to the plot. \n",
    "3. Then we use the `xaxis.set_major_locator` method to set the labels for the x-axis of the plot. \n",
    "4. The input for this function will be the result of `MaxNLocator` function from the `ticker` submodule of `matplotlib`. We can specify `integer` parameter to True, so that the label can be integers. \n",
    "5. Finally, we can use the `set_title` method of the variable ax to set the title, which we must provide as the first argument to this method. Other parameters exists including a `fontsize` parameter that takes numeric value. Increasing value, increases the font size in the plot further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcda52fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import MaxNLocator # move up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed839d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "routename79th_yearlyavg.plot(ax=ax)\n",
    "ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "ax.set_title('Average Ridership of Route 79 on Sundays and Holidays', \n",
    "             fontsize = 14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179744dd",
   "metadata": {},
   "source": [
    "Nice, so we see that until 2008 the ridership for route 79 was high and after 2008, the ridership for this route has gone down. We can repeat the above task for each routename rather easily by utilizing the `groupby` function to get the subset of data belonging to each group. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6df5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "routenames = data.groupby('routename')\n",
    "routenames.groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1b73c0",
   "metadata": {},
   "source": [
    "Note here that the `groups` method basically created a data structure where each routename and its corresponding row index labels are neatly separated by a `:`. Such data structure are called dictionary. Since this dictionary is created by `pandas`, it is a `PrettyDict` data type, which is dictionary with additional bells and whistles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceed7919",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(routenames.groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c6d766",
   "metadata": {},
   "source": [
    "<span style='color:Blue'> Dictionaries are extremely efficient way to store a collection of key-value pairs. Dictionaries are not ordered and hence cannot be indexed using index positions. There is a unique way to extract items from a dictionary, which also utilizes the `[ ]`. However, instead of index numbers, which are inexistent in dictionary, we provide the key to extract its corresponding value. </span> \n",
    "\n",
    "Below is a simple Python dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0beb4052",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_dictionary = {\"Books\":4,\n",
    "                     \"Pencil\":1,\n",
    "                     \"Pen\":2,\n",
    "                     \"Notebooks\":2}\n",
    "simple_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d07d3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(simple_dictionary[\"Books\"])\n",
    "print(simple_dictionary[\"Notebooks\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e493a3de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dir(simple_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3580a414",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_dictionary.get(\"Pen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447c38e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_dictionary.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504ea395",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_dictionary.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f3167b",
   "metadata": {},
   "source": [
    "In the case of `PrettyDict` above, the keys are the routenames and the values a list of row index labels corresponding to its routenames. So, we can use a routename to get the rows names of that route."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e07ce57",
   "metadata": {},
   "outputs": [],
   "source": [
    "routenames.groups['111th/King Drive']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaee4030",
   "metadata": {},
   "source": [
    "The above information can also be used to get a subset of the `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a63db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "route_kingdrive = data.loc[routenames.groups['111th/King Drive']]\n",
    "route_kingdrive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400a5594",
   "metadata": {},
   "source": [
    "It is possible to groupby items based on more than one group. We can specify the columns to groupby in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2dada2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_grouped = data.iloc[:,:-1].groupby(['routename', 'Month_Beginning_year']).mean()\n",
    "data_grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf9db29",
   "metadata": {},
   "source": [
    "The result is a `DataFrame` with multi-index, meaning rows have more than one index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f887e86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_grouped.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67aa625",
   "metadata": {},
   "source": [
    "This is helpful to extract information very specific information of a group. For example, now we can easily find out the average rideship information of a particular routename for a particular year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3c3c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_grouped.loc[('16th/18th', 2018)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3aea48e",
   "metadata": {},
   "source": [
    "## Exercise 1:\n",
    "Identify the 10 routes with highest number of ridership in total. Create a bar plot of total ridership of these top 10 routes. To create `bar` plot simple provide argument `bar` to the parameter `kind` of the `plot` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e048537",
   "metadata": {},
   "outputs": [],
   "source": [
    "top10routes = routenames['MonthTotal'].sum()[:10]\n",
    "top10routes.sort_values().plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4c91e9",
   "metadata": {},
   "source": [
    "## Exercise 2:\n",
    "Group the data by year to figure out the yearly average trend of ridership over the years. Plot the yearly average of the average monthly total ridership value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a605d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_groups = data.iloc[:,3:8].groupby('Month_Beginning_year').mean()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "yearly_groups['MonthTotal'].plot(ax=ax)\n",
    "ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5cca34",
   "metadata": {},
   "source": [
    "## Exercise 3:\n",
    "Now use the above grouped data to plot the average ridership during the weekdays, saturday and sunday/holidays by year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae6bce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "yearly_groups.iloc[:,:-1].plot(ax=ax)\n",
    "ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de436c17",
   "metadata": {},
   "source": [
    "Earlier, we noticed that the for routename 79th, the ridership went down after the year 2008. However, in the above plots we see that the peak of weekday ridership was in 2013 and for average saturday and sunday/holiday ridership was in 2012. Let's focus on the data past 2008 and understand the trend after this period. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873ef018",
   "metadata": {},
   "outputs": [],
   "source": [
    "after2008 = data[data['Month_Beginning']>='2009-01-01']\n",
    "after2008.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b34732e",
   "metadata": {},
   "source": [
    "[`pivot_table`](https://pandas.pydata.org/docs/reference/api/pandas.pivot_table.html) is another very useful method that provides similar functionalities to excel's pivot table. It takes parameter index, columns, values and aggfunc, which can be used to specify how we want to pivot the existing data. \n",
    "\n",
    "In the example below, we will use `pivot_table` function to calculate the mean average total montly ridership by year and month. This way not only will be know which year had the highest ridership but also which months of the year have higher ridership in general."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e9516b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot2009 = pd.pivot_table(data=after2008.iloc[:,1:], \n",
    "                           index=['Month_Beginning_year'], \n",
    "                           columns=['Month_Beginning_month'],\n",
    "                           values=['MonthTotal'],\n",
    "                           aggfunc=np.mean)\n",
    "pivot2009"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815af221",
   "metadata": {},
   "source": [
    "If we plot this data, we will basically see one line for each month over the years. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d78e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot2009.plot(kind='line')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b46193b",
   "metadata": {},
   "source": [
    "This plot can use some serious clean-up. First, instead of month as numbers, we should be able to specify month names in the legend to make it clear. For this we can use the `datetime` module and get all month of a year in a list.\n",
    "\n",
    "Second, we cannot have the legend so big that it overlaps the plot itself. To resolve this, \n",
    "1. We can increase the size of the plot by indicating the size in the `figsize` parameter of `plot` method.\n",
    "2. We can create a few columns to display the legend rather than one long columns. We can achieve this by specifying the number of columns in the `ncol` parameter of the `plt.legend` function.\n",
    "3. Finally, we can move the legend to a space in the plot that does not have graphics and give a title to legend using the `loc` parameter and `title` parameter, respectively. The `loc` parameter takes specific values only, once of which is \"lower left\" and fits out plot well.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48231b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt #move up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08400d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "months = [dt.date(2022, m, 1).strftime('%B') for m in range(1, 13)] \n",
    "print(months)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2966327b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot2009.plot(kind='line', figsize=(15,8))\n",
    "plt.legend(months, ncol=4, loc='lower left', title='Month of the year',)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32315e56",
   "metadata": {},
   "source": [
    "Did you notice that when we created the variable pivot2009, there were some missing values in the data indicated as `NaN`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7250b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot2009"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d5d6e4",
   "metadata": {},
   "source": [
    "`NaN` stands for Not a Numbers and is `pandas` default value for missing values. In our case, `NaN` indicated that we do not have any value in our data for October, November and December months for the year 2018. We can remove the `NaN` values from our data using the `dropna` method and specifying parameter `axis` as 0 to remove values by row (for columns set `axis=1`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a677ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot2009.dropna(axis=0) #do not use inplace when just testing out your code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d8ed6b",
   "metadata": {},
   "source": [
    "Note that removing `NaN` can be costly as it also get rids of the other value in the corresponding row or column that are not missing.\n",
    "\n",
    "In this `DataFrame` it was fairly easy to see all the `NaN` values but for bigger dataframe we will need to use the `isna` method to find out if there are any `NaN` values. We can use `sum` in the results `DataFrame` so that we can see the total number of missing values by columns.\n",
    "\n",
    "We can even plot this sum, so we can visually see which columns have how many missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a32ef3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot2009.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a0158f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot2009.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699b9404",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot2009.isna().sum().plot()\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e5a848",
   "metadata": {},
   "source": [
    "Instead of actual values we can also calculate the percentage of missing values for a given columns. If a huge number of values are missing in a column, it might be better to remove the column altogether from our analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbe204d",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_percent = pivot2009.isna().sum()/pivot2009.shape[0]\n",
    "missing_percent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadae190",
   "metadata": {},
   "source": [
    "Other ways of dealing with missing value is to replace it with some other value. One way to do this is to specify `fill_value` parameter in `pivot_table` method when creating the pivot table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae9fda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pivot_table(data=after2008.iloc[:,1:], \n",
    "               index=['Month_Beginning_year'], \n",
    "               columns=['Month_Beginning_month'],\n",
    "               values=['MonthTotal'],\n",
    "               aggfunc=np.mean,\n",
    "               fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bc214c",
   "metadata": {},
   "source": [
    "Alternatively, `DataFrame` has `fillna` paramter that can be used to fill missing values as well. In this case replacing missing values with 0 does not make much sense. It would be a better reference to replace this value with the average value of ridership for that month. So let's calculate the average of each columns, which will give us the monthly average ridership. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b670125e",
   "metadata": {},
   "outputs": [],
   "source": [
    "monthlyavg_2009 = pivot2009.mean(axis=0)\n",
    "monthlyavg_2009"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213d0b74",
   "metadata": {},
   "source": [
    "Now, we can use the last three values to replace the last three missing value in `DataFrame` pivot2009. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5734601d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot2009.fillna(monthlyavg_2009[-3:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a5bce6",
   "metadata": {},
   "source": [
    "It might be still questionable to replace this value average because such an average does not take into account the time series component of the ridership. A better value might be to calculate the rolling average, which can be done by using the `rolling` parameter. We can specify how many data points we want to use to calculate the rolling statistics and then chain the `mean` function to it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af80e24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot2009.iloc[:,-3:].rolling(2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0e41ee",
   "metadata": {},
   "source": [
    "Since we are only interested in the value of the last rolling mean, we can isolate those values using the `iloc` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4cc789",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot2009.rolling(2).mean().iloc[-2,-3:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c300033",
   "metadata": {},
   "source": [
    "Now, we are ready to replace the missing values with these rolling mean values. This time when using `fillna` we will specify the value of `inplace` paramter to True. This is make our change permanent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1d1142",
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_mean = pivot2009.rolling(2).mean().iloc[-2,-3:]\n",
    "pivot2009.fillna(rolling_mean, inplace=True)\n",
    "pivot2009.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c72cacd",
   "metadata": {},
   "source": [
    "## Additional Exercises: \n",
    "\n",
    "1. Which routes have the highest difference in average ridership between weekdays and Saturdays?\n",
    "2. Which routes have the highest difference in average ridership between weekdays and Sundays/Holidays?\n",
    "3. Which routes have the most consistent average ridership between weekdays, Saturdays and Sundays/Holidays? i.e. are there any route that are not affected by the day of the week?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
